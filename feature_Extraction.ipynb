{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "This module intend to find the most important features for a given classification task. The main idea is to train a neural net and verify the acuracy of the predictions when ommiting a set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \n",
    "    s=1/(1+math.exp(-x))\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/229 [==============================] - 0s 56us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\n",
      "acc: 70.31%\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(20)\n",
    "# load pima indians dataset\n",
    "dataset = np.loadtxt(\"./Final_IC/pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[0:538,0:8]\n",
    "Y = dataset[0:538,8]\n",
    "X_test = dataset[539:768,0:8]\n",
    "Y_test = dataset[539:768,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64,input_dim=8, activation='sigmoid'))\n",
    "#model.add(Dense(64,input_dim=8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=200, batch_size=5, verbose=False)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    s = max(0,x)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(model.get_weights()[3] - model.get_weights()[3])\n",
    "features_correlated=[]\n",
    "taxa_de_acerto=[]\n",
    "for K in range(8):\n",
    "    saida=[]\n",
    "    W1= model.get_weights()[0].T\n",
    "    for nr_index in range(len(W1)):\n",
    "        for wn_index in range(len(W1[nr_index])):\n",
    "            if wn_index!=K :\n",
    "                W1[nr_index][wn_index]=0\n",
    "    for j in range(len(X_test)):\n",
    "        N1=[]\n",
    "        for i in range(64):\n",
    "            N1.append(sigmoid((sum((np.multiply(W1,X_test[j])).T))[i]+model.get_weights()[1][i]))\n",
    "        saida.append(round(sigmoid((sum(np.multiply(N1,model.get_weights()[2].T)[0])+model.get_weights()[3]))))\n",
    "    predicted=model.predict(X_test)\n",
    "    counter_acerto=0\n",
    "    counter_acerto1=0\n",
    "    counter_erros0=0\n",
    "    counter_erros1=0\n",
    "    counter_de_0=0\n",
    "    counter_de_1=0\n",
    "    for i in range(len(predicted)):\n",
    "        if round(predicted[i][0])==0:\n",
    "            if saida[i]==round(predicted[i][0]):\n",
    "                counter_acerto+=1\n",
    "            else:\n",
    "                counter_erros0+=1\n",
    "            counter_de_0+=1\n",
    "        if round(predicted[i][0])==1:\n",
    "            if saida[i]==round(predicted[i][0]):\n",
    "                counter_acerto1+=1\n",
    "            else:\n",
    "                counter_erros1+=1\n",
    "            counter_de_1+=1    \n",
    "    taxa_acerto = counter_acerto/counter_de_0\n",
    "    taxa_erro = counter_erros0/counter_de_0\n",
    "    taxa_acerto1 = counter_acerto1/counter_de_1\n",
    "    taxa_erro1 = counter_erros1/counter_de_1\n",
    "    taxa_final = (((taxa_acerto+taxa_acerto1)/2) )\n",
    "    #print (taxa_final)\n",
    "    if taxa_final >0:\n",
    "        features_correlated.append(K)\n",
    "        taxa_de_acerto.append(taxa_final)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#(model.get_weights()[3] - model.get_weights()[3])\n",
    "features_correlated_comb=[]\n",
    "taxa_acerto_comb = []\n",
    "times=[]\n",
    "for k in range(8):\n",
    "    result_test = itertools.combinations(range(8), k)\n",
    "    for comb in result_test:\n",
    "        starttime = time.time()\n",
    "        saida=[]\n",
    "        W1= model.get_weights()[0].T\n",
    "        for nr_index in range(len(W1)):\n",
    "            for wn_index in range(len(W1[nr_index])):\n",
    "                if wn_index not in comb :\n",
    "                    W1[nr_index][wn_index]=0\n",
    "        for j in range(len(X_test)):\n",
    "            N1=[]\n",
    "            \n",
    "            for i in range(64):\n",
    "                N1.append(sigmoid((sum((np.multiply(W1,X_test[j])).T))[i]+model.get_weights()[1][i]))\n",
    "            saida.append(round(sigmoid((sum(np.multiply(N1,model.get_weights()[2].T)[0])+model.get_weights()[3]))))\n",
    "        predicted=model.predict(X_test)\n",
    "        counter_acerto=0\n",
    "        counter_acerto1=0\n",
    "        counter_erros0=0\n",
    "        counter_erros1=0\n",
    "        counter_de_0=0\n",
    "        counter_de_1=0\n",
    "        for i in range(len(predicted)):\n",
    "            if round(predicted[i][0])==0:\n",
    "                if saida[i]==round(predicted[i][0]):\n",
    "                    counter_acerto+=1\n",
    "                else:\n",
    "                    counter_erros0+=1\n",
    "                counter_de_0+=1\n",
    "            if round(predicted[i][0])==1:\n",
    "                if saida[i]==round(predicted[i][0]):\n",
    "                    counter_acerto1+=1\n",
    "                else:\n",
    "                    counter_erros1+=1\n",
    "                counter_de_1+=1    \n",
    "        taxa_acerto = counter_acerto/counter_de_0\n",
    "        taxa_erro = counter_erros0/counter_de_0\n",
    "        taxa_acerto1 = counter_acerto1/counter_de_1\n",
    "        taxa_erro1 = counter_erros1/counter_de_1\n",
    "        taxa_final = (((taxa_acerto+taxa_acerto1)/2) )\n",
    "        #print (taxa_final)\n",
    "        if taxa_final >0:\n",
    "            features_correlated_comb.append(comb)\n",
    "            taxa_acerto_comb.append(taxa_final)\n",
    "        times.append(time.time()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,) 0.6563299232736572\n",
      "(0, 6) 0.6728169528681038\n",
      "(0, 3, 6) 0.6854219948849105\n",
      "(0, 5, 6, 7) 0.6359152356594812\n",
      "(0, 1, 2, 5, 7) 0.7648428936792109\n",
      "(0, 1, 2, 5, 6, 7) 0.8069967117281696\n",
      "(0, 1, 2, 3, 4, 5, 7) 0.9338235294117647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "taxa_acerto_comb, features_correlated_comb = zip(*sorted(zip(taxa_acerto_comb, features_correlated_comb),reverse=True))\n",
    "for i in range(1,8):\n",
    "    for comb in range(len(features_correlated_comb)):  \n",
    "        if len(features_correlated_comb[comb])==i:\n",
    "            print (features_correlated_comb[comb],taxa_acerto_comb[comb])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get most important feature_value\n",
    "\n",
    "It was not fully implemented because in the early research the time to compute the combinations was too high. A possible alternative is to use heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''result_test = itertools.combinations(range(8), 7)\n",
    "countii = 0\n",
    "for comb in result_test:\n",
    "    print (comb)\n",
    "    countii+=1\n",
    "countii'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''X_train = pd.DataFrame(dataset[:,0:8])\n",
    "X_train_dummy = pd.DataFrame()\n",
    "for col in X_train.columns:\n",
    "    for val in (np.unique(X_train[col])):\n",
    "        colname=str(col)+\"_\"+str(val)\n",
    "        \n",
    "        X_train_dummy[colname]= X_train[col]==val'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''X = np.asarray(X_train_dummy[0:668])\n",
    "X_test = np.asarray(X_train_dummy[669:768])\n",
    "Y = dataset[0:668,8]\n",
    "Y_test = dataset[669:768,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(64,input_dim=len(X_train_dummy.columns), activation='sigmoid'))\n",
    "#model.add(Dense(64,input_dim=8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=200, batch_size=1, verbose=False)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''#(model.get_weights()[3] - model.get_weights()[3])\n",
    "features_correlated_comb=[]\n",
    "taxa_acerto_comb = []\n",
    "times=[]\n",
    "for k in range(1,2):\n",
    "    result_test = itertools.combinations(range(len(X_train_dummy.columns)), k)\n",
    "    for comb in result_test:\n",
    "        starttime = time.time()\n",
    "        saida=[]\n",
    "        W1= model.get_weights()[0].T\n",
    "        for nr_index in range(len(W1)):\n",
    "            for wn_index in range(len(W1[nr_index])):\n",
    "                if wn_index not in comb :\n",
    "                    W1[nr_index][wn_index]=0\n",
    "        \n",
    "        for j in range(len(X_test)):\n",
    "            N1=[]\n",
    "            for i in range(64):\n",
    "                N1.append(sigmoid((sum((np.multiply(W1,X_test[j])).T))[i]+model.get_weights()[1][i]))\n",
    "            saida.append(round(sigmoid((sum(np.multiply(N1,model.get_weights()[2].T)[0])+model.get_weights()[3]))))\n",
    "        predicted=model.predict(X_test)\n",
    "        \n",
    "        \n",
    "        counter_acerto=0\n",
    "        counter_acerto1=0\n",
    "        counter_erros0=0\n",
    "        counter_erros1=0\n",
    "        counter_de_0=0\n",
    "        counter_de_1=0\n",
    "        for i in range(len(predicted)):\n",
    "            if round(predicted[i][0])==0:\n",
    "                if saida[i]==round(predicted[i][0]):\n",
    "                    counter_acerto+=1\n",
    "                else:\n",
    "                    counter_erros0+=1\n",
    "                counter_de_0+=1\n",
    "            if round(predicted[i][0])==1:\n",
    "                if saida[i]==round(predicted[i][0]):\n",
    "                    counter_acerto1+=1\n",
    "                else:\n",
    "                    counter_erros1+=1\n",
    "                counter_de_1+=1    \n",
    "        taxa_acerto = counter_acerto/counter_de_0\n",
    "        taxa_erro = counter_erros0/counter_de_0\n",
    "        taxa_acerto1 = counter_acerto1/counter_de_1\n",
    "        taxa_erro1 = counter_erros1/counter_de_1\n",
    "        taxa_final = (((taxa_acerto+taxa_acerto1)/2) - ((taxa_erro+taxa_erro1)/2))\n",
    "        print(comb)\n",
    "        print (taxa_final)\n",
    "        if taxa_final >0:\n",
    "            features_correlated_comb.append(comb)\n",
    "            taxa_acerto_comb.append(taxa_final)\n",
    "        \n",
    "        times.append(time.time()-starttime)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''dataset_frame = pd.DataFrame(dataset)\n",
    "dataset_frame'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
